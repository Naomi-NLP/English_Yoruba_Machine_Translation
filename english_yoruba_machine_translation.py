# -*- coding: utf-8 -*-
"""English- Yoruba Machine Translation

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1XaIIB33wYpcObS2ar6uxjXd-Yc-Xgzx4
"""

!pip install -U transformers

!pip install transformers sentencepiece sacremoses
!pip install torch

# Load your CSV
import pandas as pd
MT_data = "/content/drive/MyDrive/MT.csv"
df = pd.read_csv(MT_data)

# Check first rows
df.head()
df.columns

df.shape

# Randomly sample 300 rows from the dataframe for analysis
df_sample = df.sample(n=300, random_state=42).reset_index(drop=True)
df_sample.shape

from transformers import AutoModelForSeq2SeqLM, AutoTokenizer
import torch
from tqdm import tqdm
import os

torch.cuda.is_available()

# Use a pipeline as a high-level helper
from transformers import pipeline

pipe = pipeline("translation", model="facebook/nllb-200-distilled-1.3B")

model_name = "facebook/nllb-200-distilled-600M"
src_lang = "eng_Latn"
tgt_lang = "yor_Latn"

print("Loading model...")
tokenizer = AutoTokenizer.from_pretrained(model_name, src_lang=src_lang)

model = AutoModelForSeq2SeqLM.from_pretrained(model_name)
device = "cuda" if torch.cuda.is_available() else "cpu"
model = model.to(device)

def translate_batch(texts, batch_size=8):
    translations = []
    for i in tqdm(range(0, len(texts), batch_size), desc="Translating"):
        batch = [str(t) if pd.notna(t) else "" for t in texts[i:i+batch_size]]
        inputs = tokenizer(batch, return_tensors="pt", padding=True, truncation=True, max_length=512).to(device)
        translated_tokens = model.generate(
            **inputs,
            forced_bos_token_id=tokenizer._convert_token_to_id_with_added_voc(tgt_lang),
            max_length=512
        )
        batch_translations = tokenizer.batch_decode(translated_tokens, skip_special_tokens=True)
        translations.extend(batch_translations)
    return translations

def process_file(input_path, output_path1, output_path2):
    print(f"Processing {input_path}...")
    df_sample = pd.read_csv(input_path, sep=",")

df_translated = df_sample.copy()

print("Translating english column...")

# Translate the english column
df_translated["Yoruba_translated_model_output"] = translate_batch(df_sample["English"].tolist(), batch_size=8)

# Define the output path
output_path = "/content/drive/MyDrive/translated_MT.csv"

# Save to CSV
df_translated.to_csv(output_path, index=False)

print(f"Saved translated file {output_path}")

df1 = pd.read_csv("/content/drive/MyDrive/translated_MT.csv")
df1.head(20)

df1.shape

"""Evaluation"""

!pip install sacrebleu evaluate

!pip install bert_score

import evaluate

# Load metrics
bleu = evaluate.load("sacrebleu")
meteor = evaluate.load("meteor")
bertscore = evaluate.load("bertscore")

# References and predictions
predictions = df["Yoruba_translated_model_output"].tolist()
references = [[ref] for ref in df["Yoruba"].tolist()]

bleu_refs = [[r[0]] for r in references]
flat_refs = [r[0] for r in references]

# BLEU
bleu_score = bleu.compute(predictions=predictions, references=bleu_refs)
print("BLEU:", bleu_score)

# METEOR
meteor_score = meteor.compute(predictions=predictions, references=flat_refs)
print("METEOR:", meteor_score)

# BERTScore
bertscore_score = bertscore.compute(predictions=predictions, references=flat_refs, lang="en")
print("BERTScore:", bertscore_score)